{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HamidBekamiri/Blog-Posts/blob/main/FuzzyDataMatchingWithGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Title: Fuzzy Data Matching with GPT-based Embeddings and Nearest Neighbors\n"
      ],
      "metadata": {
        "id": "ETwPWKmpg4rx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##High-Level Executive Summary:\n",
        "Data matching, the process of identifying similar records across multiple datasets, is a common challenge in data management. In this code, we will use a powerful approach to fuzzy data matching using GPT-based embeddings and Nearest Neighbors. We demonstrate how to leverage the OpenAI GPT model to generate embeddings for textual data and utilize the Nearest Neighbors algorithm for finding close matches. By following the provided code and explanations, you'll be equipped with a practical solution to efficiently match fuzzy records across datasets."
      ],
      "metadata": {
        "id": "uLBVM0PtiEbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "os.environ['OPENAI_API_KEY'] = 'sk-'\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "NgnWEm2dKxQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yfVavtBq6jrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import pandas as pd\n",
        "\n",
        "def get_embedding(text):\n",
        "    result = openai.Embedding.create(\n",
        "      model='text-embedding-ada-002',\n",
        "      input=text\n",
        "    )\n",
        "    return result[\"data\"][0][\"embedding\"]\n",
        "\n",
        "def fuzzy_match(target_df, source_df, columns, threshold=0.85):\n",
        "    \"\"\"\n",
        "    Function to perform fuzzy matching between two dataframes on specified columns.\n",
        "\n",
        "    Parameters:\n",
        "    target_df (pd.DataFrame): The dataframe to be matched to.\n",
        "    source_df (pd.DataFrame): The dataframe to be matched from.\n",
        "    columns (list of str): The columns to perform fuzzy matching on.\n",
        "    threshold (float, optional): The cosine similarity threshold for a match to be considered 'good'. Defaults to 0.85.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A new dataframe where each specified column in source_df is matched against the corresponding column in target_df,\n",
        "                  with similarity scores and 'good'/'bad' match indicators for each column.\n",
        "    \"\"\"\n",
        "\n",
        "    matched_results = source_df[columns].copy()\n",
        "\n",
        "    for column in columns:\n",
        "        target_df[column + '_embeddings'] = target_df[column].apply(get_embedding)\n",
        "        source_df[column + '_embeddings'] = source_df[column].apply(get_embedding)\n",
        "\n",
        "        nn = NearestNeighbors(n_neighbors=1, metric='cosine').fit(target_df[column + '_embeddings'].to_list())\n",
        "        distances, indices = nn.kneighbors(source_df[column + '_embeddings'].to_list(), return_distance=True)\n",
        "\n",
        "        matched_results[column + '_matched_to'] = [target_df.loc[indices[i, 0], column] for i in range(source_df.shape[0])]\n",
        "        matched_results[column + '_similarity'] = 1 - distances\n",
        "        matched_results[column + '_is_good_match'] = ['good' if 1 - distances[i, 0] >= threshold else 'bad' for i in range(source_df.shape[0])]\n",
        "\n",
        "    return matched_results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "WQyfV82coxGg",
        "outputId": "ec435657-8645-419e-c76d-349966708d14"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b7c71b17ca39>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have two dataframes df1 and df2 with 'name' and 'address' fields\n",
        "df1 = pd.DataFrame({\n",
        "    'name': ['John Doe', 'Mary Jane', 'Peter Parker'],\n",
        "    'address': ['123 Main St', '456 Oak St', '789 Pine St'],\n",
        "    'age': ['10','25','100'],\n",
        "})\n",
        "\n",
        "df2 = pd.DataFrame({\n",
        "    'name': ['Pete Parker', 'Jon Doe', 'John Doe', 'Marry Jane', 'Anita Smith'],\n",
        "    'address': ['123 Main Street', '457 Oak St', '457', '789 Pine Street', '789'],\n",
        "    'age': ['10','30','40','90',''],\n",
        "})"
      ],
      "metadata": {
        "id": "XZGTf0HF5vF_",
        "outputId": "89afaae3-bc23-4e95-e29a-49742ce46be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6aa571ed34ca>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assuming you have two dataframes df1 and df2 with 'name' and 'address' fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m df1 = pd.DataFrame({\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'John Doe'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mary Jane'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Peter Parker'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'address'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'123 Main St'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'456 Oak St'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'789 Pine St'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'age'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'10'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'25'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'100'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ow6Yv6Ec5yS4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}